{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac44c126-7023-4742-bca7-bceedab3f312",
   "metadata": {},
   "source": [
    "## Mini Project 1: Least Squares Based Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd518d-f503-4ef3-ab13-40c080d390e9",
   "metadata": {},
   "source": [
    "#### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24870597-8968-4d9b-89aa-d34f713ee064",
   "metadata": {},
   "source": [
    "The below splits the contents of `mnist.mat` into 60,000 training image/label pairs, and 10,000 testing image/label pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae1ecd0-112a-4d7e-a9e1-a7bd374d4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat_contents = scipy.io.loadmat('mnist', appendmat=True)\n",
    "trainImages = mat_contents['trainX'] # trainImages.shape returns (60000, 784)\n",
    "trainLabels = mat_contents['trainY'] # trainLabels.shape returns (1, 60000)\n",
    "testImages = mat_contents['testX']   # testLabels.shape returns (10000, 784)\n",
    "testLabels = mat_contents['testY']   # testLabels.shape returns (1, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb79d34-355a-4693-bf85-6e8997e17095",
   "metadata": {},
   "source": [
    "Here, I am visualizing ten random handwritten digits using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ff24c9-ae5b-47c0-b833-08f1aeeec004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Reshape the images from (60000, 784) to (60000, 28, 28)\n",
    "displayImages = trainImages.reshape(60000, 28, 28)\n",
    "\n",
    "# Transpose the labels to (60000,)\n",
    "displayLabels = trainLabels.squeeze()\n",
    "\n",
    "# Visualize 10 random images and labels\n",
    "for i in range(10):\n",
    "    rand = random.randint(0,59991)\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(displayImages[rand], cmap='gray')\n",
    "    plt.title(f\"Label: {displayLabels[rand]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb1ffe-fecc-484b-9074-3895e204be3b",
   "metadata": {},
   "source": [
    "#### Problem 1: Least Squares Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c306ae-56e2-4f18-9bef-13f6b5bc0a3f",
   "metadata": {},
   "source": [
    "##### Task 1\n",
    "Write your own code to implement the (i) one-versus-one and (ii) one-versus-all multi-class classifier using the binary classifier as building blocks. Your code should take appropriately labeled training data as the input, and determine the weights of the constituent binary classifiers as the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ceec80-677c-4163-981c-cf6da129873b",
   "metadata": {},
   "source": [
    "##### Binary classifier building block\n",
    "Given $N$ data points $\\left\\{ (\\mathbf{\\vec{x}_1}, y_1), \\ldots, (\\mathbf{\\vec{x}_N}, y_N) \\right\\}$\n",
    " where $x_i$ denotes the $i^{th}$ feature vector and $y_i \\in \\left\\{ -1, 1 \\right\\}$ is the corresponding label for each data point. Given $N$ training data points, we try to find the best linear regression model by solving the following least squares problem:\n",
    "$$ \\operatorname{min}_{\\beta, \\alpha} \\sum_{i = 1}^N \\left( y_i - \\mathbf{\\beta^T \\vec{x}_i} - \\alpha \\right)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9438b72a-c66c-494f-a033-0286cf7e07b7",
   "metadata": {},
   "source": [
    "Finding the best linear regression model cannot be found by simply solving $\\mathbf{A\\vec{x}}= \\mathbf{\\vec{y}}$, where\n",
    "\n",
    "$$ \n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "x^{(1)}_1 & x^{(1)}_2 & \\cdots & x^{(1)}_n & 1 \\\\\n",
    "x^{(2)}_1 & x^{(2)}_2 & \\cdots & x^{(2)}_n & 1 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "x^{(L)}_1 & x^{(L)}_2 & \\cdots & x^{(L)}_n & 1 \\\\\n",
    "\\end{bmatrix},\n",
    "\\mathbf{\\vec{x}} = \\begin{bmatrix}\n",
    "\\beta_1 \\\\\n",
    "\\beta_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\beta_n \\\\\n",
    "\\alpha\n",
    "\\end{bmatrix},\n",
    "\\mathbf{\\vec{y}} = \\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_k\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and $L$ is the number of samples of $\\mathbf{\\vec{x}}$ and $n$ is the size of the feature vectors. This is because we are not guaranteed that $\\mathbf{\\vec{x}} \\in \\mathcal{R}(\\mathbf{A})$. Finding the least squares solution $\\mathbf{\\vec{x}^*}$ where $\\mathbf{A\\vec{x}^*}$ is as close to $\\mathbf{\\vec{y}}$ as possible is equivalent to minimizing the length between $\\mathbf{\\vec{y}}$ and $\\mathbf{A\\vec{x}^*}$ as defined above. From lecture, the notion of length we want to minimize is the $\\ell_2$ norm as defined as:\n",
    "\n",
    "$$|| \\mathbf{\\vec{y}} - \\mathbf{A\\vec{x}^*}||_2^2 = \\left( \\sqrt{\\sum_{i = 1}^N \\left( y_i - \\mathbf{\\beta^T \\vec{x}_i} - \\alpha \\right)^2} \\right)^2 = \\sum_{i = 1}^N \\left( y_i - \\mathbf{\\beta^T \\vec{x}_i} - \\alpha \\right)^2$$\n",
    "\n",
    "From homework 2, we know the closest vector $\\mathbf{A\\vec{x}^*}$ (i.e. our best approximation) is the projection of the vector $\\mathbf{\\vec{y}}$ onto $\\mathcal{R}(\\mathbf{A})$ (or the minimum $\\ell_2$ norm). This means that the vector from $\\mathbf{A\\vec{x}^*}$ to $\\mathbf{\\vec{y}}$ is orthogonal to $\\mathcal{R}(\\mathbf{A})$. Expressing this vector as $\\mathbf{A\\vec{x}^*} - \\mathbf{\\vec{y}}$, we can write:\n",
    "\n",
    "$$\\mathbf{A^T}(\\mathbf{A\\vec{x}^*} - \\mathbf{\\vec{y}}) = \\mathbf{\\vec{0}}$$\n",
    "\n",
    "Here, $\\mathbf{A\\vec{x}^*} - \\mathbf{\\vec{y}} \\in \\mathcal{N}(\\mathbf{A^T})$. Now to rewrite this in terms of $\\mathbf{\\vec{x}^*}$, we can perform the following operations:\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "\\mathbf{A^T}(\\mathbf{A\\vec{x}^*} - \\mathbf{\\vec{y}}) &= \\mathbf{\\vec{0}} \\\\\n",
    "\\mathbf{A^T A\\vec{x}^*} - \\mathbf{A^T \\vec{y}} &= \\mathbf{\\vec{0}} \\\\\n",
    "\\mathbf{A^T A\\vec{x}^*} &= \\mathbf{A^T \\vec{y}} \\\\\n",
    "\\mathbf{\\vec{x}}^* &= \\mathbf{\\left( A^T A \\right)^{-1} A^T \\vec{y}}\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c58661-c81e-496b-be18-f843c064a84d",
   "metadata": {},
   "source": [
    "Now, let us format the MNIST data appropriately such that we can solve the above equation. Firstly, let us get $\\mathbf{A}$ by appending an intercept term to our dataset such that `trainImages.shape` returns `(60000, 785)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a20adee2-d837-4afe-b48f-7f78e694195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# A.shape returns (60000, 784)\n",
    "A = mat_contents['trainX']\n",
    "\n",
    "# normalizing the data\n",
    "A_n = A / 255.0\n",
    "\n",
    "# A.shape returns (60000, 785)\n",
    "A = np.column_stack((A_n, np.ones(60000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14933fb-e512-4949-b7e8-c17853b55473",
   "metadata": {},
   "source": [
    "Here, $\\mathbf{A}$ is a $60000 \\times 785$ matrix. Now, we need to find $\\mathbf{\\vec{y}}$. Since $y_i \\in \\left\\{ -1, 1 \\right\\}$, we need to determine which number we are looking for. For now, let's stick with $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd6ef9cb-74ad-4110-b7dd-e78b967b935d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, ..., -1, -1, -1]], dtype=int8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y.shape returns (1, 60000)\n",
    "Y = mat_contents['trainY']\n",
    "Y = Y.astype('int8')\n",
    "\n",
    "# Replacing every value that isn't 1 with -1\n",
    "for i in range(Y.shape[1]):\n",
    "    if (Y[0, i] != 1):\n",
    "        Y[0, i] = -1\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a07eb7b-f71d-4b97-9851-ac62dfb32eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, ..., -1, -1, -1]], dtype=int8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a335619-dcc6-4d91-9b6b-6742dc49c27b",
   "metadata": {},
   "source": [
    "Let $\\mathbf{\\beta^*}, \\alpha^*$ be the solution to the above problem. Then the **binary least squares classifier** $\\mathbf{\\hat{f}(x)}$ is given by\n",
    "$$ \\hat{f}(\\mathbf{x}) = \\operatorname{sign}(\\mathbf{{\\beta^*}^T x} + \\alpha^*)$$\n",
    "for arbitrary test data **x**. Here $\\operatorname{sign}(a) = 1$ for $a \\geq 0$ and $-1$ for $a < 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ae1a7-0414-417b-b36a-c36279e268b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc3122c-d5d4-4a71-89b1-016151394eab",
   "metadata": {},
   "source": [
    "##### Task 2\n",
    "Evaluate the training error of both classifiers using error rate and confusion matrix:\n",
    "- The error rate is the total number of errors in predicted label divided by the total number of inputs being classified.\n",
    "- Confusion matrix (ref. Pg. 287 and 298 from textbook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a11105-2f8b-49fc-bd82-46894c3b63b0",
   "metadata": {},
   "source": [
    "##### Task 3\n",
    "Evaluate the performance of both multi-class classifiers on the test data. Comment on their performance. How well do they generalize on the test data? Which digits are easy to recognize, which ones are harder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17290655-a5a6-4720-87cb-ae9657a54832",
   "metadata": {},
   "source": [
    "#### Problem 2: Randomized Feature Based Least Square Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96312ea0-a4a6-4cdf-a697-88e9626f3873",
   "metadata": {},
   "source": [
    "##### Task 1\n",
    "Modify the code for Problem 1 to learn the multi-class classifier in the feature space. Use the following non-linear mappings to construct your feature vectors:\n",
    "- **Identity Function:** $ g(x) = x $\n",
    "- **Sigmoid Function:** $ g(x) = \\frac{1}{1 + e^{-x}} $\n",
    "- **Sinusoidal Function:** $ g(x) = \\operatorname{sin}(x) $\n",
    "- **Rectified Linear Unit (ReLU) Function:** $ g(x) = max(x,0) $\n",
    " \n",
    "Assume that $L = 1000$ for this part. Compare the classification performance for different choices of the feature mapping by changing the non-linearity. Do these feature mappings perform better than the classifier learnt in Problem 2 on (i) Training data (ii) Testing data? Which feature mapping generalizes well, i.e., continues to perform well on the testing data? Discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c4c858-fed9-4d19-b053-596c912809a3",
   "metadata": {},
   "source": [
    "##### Task 2\n",
    "Vary the number of features $L$, and plot the error rate as a function of the number of features $L$. Comment on how adding more features affects your classifier design."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
